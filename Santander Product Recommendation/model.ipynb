{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "from operator import sub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing, ensemble\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from getTrain import *\n",
    "from getPredictData import *\n",
    "from preprocessFunction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train\n",
    "- ### get the train_all, train_null data and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path=\"/media/chen/0009C4D1000728AE/Santander Product Recommendation/\"\n",
    "f=open(data_path+\"train_ver2.csv\")\n",
    "null_x_1,null_y_1=get_train_null(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path=\"/media/chen/0009C4D1000728AE/Santander Product Recommendation/\"\n",
    "\n",
    "f=open(data_path+\"train_ver2.csv\")\n",
    "null_x_1,null_y_1=get_train_null(f)\n",
    "np.savez(\"null_all.npz\",(null_x_1,null_y_1))\n",
    "\n",
    "f=open(data_path+\"train_ver2.csv\")\n",
    "train_x_1,train_y_1=processData_train(f)\n",
    "f.close()\n",
    "np.savez(\"lessMore.npz\",(train_x_1,train_y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### load the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "daLoad=np.load(\"lessMore.npz\")['arr_0']\n",
    "train_x_1,train_y_1=daLoad[0],daLoad[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### split train_all data into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_x,null_y,have_x,have_y=[],[],[],[]\n",
    "for m,n in zip(train_x_1,train_y_1):\n",
    "    if sum(m[18:])==0:\n",
    "        for i,j in enumerate(n):\n",
    "            if j>0:\n",
    "                null_x.append(m)\n",
    "                null_y.append(i)\n",
    "    else:\n",
    "        for i,j in enumerate(n):\n",
    "            if j>0:\n",
    "                have_x.append(m)\n",
    "                have_y.append(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ###  preprocess the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tr_x,Tr_y=[],[]\n",
    "for m,n in zip(train_x_1,train_y_1):\n",
    "    for i,j in enumerate(n):\n",
    "        if j>0:\n",
    "            Tr_x.append(m)\n",
    "            Tr_y.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict\n",
    "- ### get the predict data and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1=open(data_path+\"train_ver2.csv\")\n",
    "cust_dict_5=processData_test_1(f1)\n",
    "f1.close()\n",
    "f2=open(data_path+\"test_ver2.csv\")\n",
    "test_x_1,test_y_1=processData_test_2(f2,cust_dict_5)\n",
    "f2.close()\n",
    "np.savez(\"predict_0628.npz\",(test_x_1,test_y_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr=np.load(\"predict_0628.npz\")\n",
    "test_x_1,test_y_1=arr['arr_0'][0],arr['arr_0'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### split predict_all data into two parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "null_tx,null_ty,have_tx,have_ty=[],[],[],[]\n",
    "for m,n in zip(test_x_1,test_y_1):\n",
    "    if sum(m[18:])==0:\n",
    "        for i,j in enumerate(n):\n",
    "            if j>0:\n",
    "                null_tx.append(m)\n",
    "                null_ty.append(i)\n",
    "    else:\n",
    "        for i,j in enumerate(n):\n",
    "            if j>0:\n",
    "                have_tx.append(m)\n",
    "                have_ty.append(i)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model\n",
    "- ### xgboost of train_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_xgboost():\n",
    "\tparam = {}\n",
    "\tparam['booster']='gbtree'\n",
    "\tparam['objective'] = 'multi:softprob'\n",
    "\tparam['eta'] = 0.05\n",
    "\tparam['max_depth'] = 8\n",
    "\tparam['silent'] = 1\n",
    "\tparam['num_class'] = 24\n",
    "\tparam['eval_metric'] = \"mlogloss\"\n",
    "\tparam['min_child_weight'] = 2\n",
    "\tparam['subsample'] = 1\n",
    "\tparam['colsample_bytree'] = 0.9\n",
    "\tparam['seed'] = 0\n",
    "\tparam['nthread']=8    \n",
    "\t#param['alpha']=0.2\n",
    "\t#param['lambda']=0.5\n",
    "\tnum_rounds = 110\n",
    "\tglobal target_cols\n",
    "\tplst = list(param.items())\n",
    "\treturn plst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### cv to find the best n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model=xgb.cv(model_xgboost(),xgb.DMatrix(Tr_x,label=Tr_y),num_boost_round=100,nfold=5,early_stopping_rounds=10,seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### gridsearch to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param={'max_depth':range(3,10,2),'min_child_weight':range(1,5,2)}\n",
    "scv=GridSearchCV(XGBClassifier(max_depth=6,min_child_weight=3,n_estimators=29,\n",
    "                               learning_rate=0.3,subsample=1,colsample_bytree=0.9,objective='multi:softprob'),param_grid=param,\n",
    "                 cv=5,n_jobs=4)\n",
    "import datetime\n",
    "begin=datetime.datetime.now()\n",
    "scv.fit(np.array(Tr_x),np.array(Tr_y))\n",
    "print datetime.datetime.now()-begin\n",
    "scv.get_params,scv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgtrain=xgb.DMatrix(null_x,label=null_y)\n",
    "params=model_xgboost()\n",
    "from sklearn.cross_validation import train_test_split\n",
    "tr_x,te_x,tr_y,te_y=train_test_split(have_x,have_y,train_size=0.8)\n",
    "xgtrain,xgtest=xgb.DMatrix(tr_x,label=tr_y),xgb.DMatrix(te_x,label=te_y)\n",
    "model=xgb.train(params,xgtrain,210,evals=[(xgtrain,'train'),(xgtest,'test')],early_stopping_rounds=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# null and have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_tx,null_ty,have_tx,have_ty=[],[],[],[]\n",
    "for m,n in zip(null_x_1,null_y_1):\n",
    "        for i,j in enumerate(n):\n",
    "            if j>0:\n",
    "                null_tx.append(m)\n",
    "                null_ty.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgboost of null and have\n",
    "- # null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_xgboost():\n",
    "\tparam = {}\n",
    "\tparam['booster']='gbtree'\n",
    "\tparam['objective'] = 'multi:softprob'\n",
    "\tparam['eta'] = 0.1\n",
    "\tparam['max_depth'] = 8\n",
    "\tparam['silent'] = 1\n",
    "\tparam['num_class'] = 24\n",
    "\tparam['eval_metric'] = \"mlogloss\"\n",
    "\tparam['min_child_weight'] = 2\n",
    "\tparam['subsample'] = 0.9\n",
    "\tparam['colsample_bytree'] = 0.9\n",
    "\tparam['seed'] = 0\n",
    "\tparam['nthread']=8    \n",
    "\t#param['alpha']=0.2\n",
    "\t#param['lambda']=0.8\n",
    "\tnum_rounds = 110\n",
    "\tglobal target_cols\n",
    "\tplst = list(param.items())\n",
    "\treturn plst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr_x,te_x,tr_y,te_y=cross_validation.train_test_split(null_tx,null_ty,train_size=0.8,random_state=0)\n",
    "xgtrain=xgb.DMatrix(tr_x,label=tr_y)\n",
    "xgtest=xgb.DMatrix(te_x,label=te_y)\n",
    "model_null=xgb.train(model_xgboost(),xgtrain,150,evals=[(xgtrain,'train'),(xgtest,'test')],\n",
    "                     evals_result={'eval_metric':'auc'},early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### grid_search to find the best number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param={\"max_depth\":range(12,15,1)}\n",
    "scv=GridSearchCV(XGBClassifier(max_depth=12,min_child_weight=1,learning_rate=0.1,n_estimators=60,subsample=1,\n",
    "                               colsample_bytree=0.9,objective=\"multi:softprob\"),param_grid=param,cv=5,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- # have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def model_xgboost():\n",
    "\tparam = {}\n",
    "\tparam['booster']='gbtree'\n",
    "\tparam['objective'] = 'multi:softprob'\n",
    "\tparam['eta'] = 0.1\n",
    "\tparam['max_depth'] = 6\n",
    "\tparam['silent'] = 1\n",
    "\tparam['num_class'] = 24\n",
    "\tparam['eval_metric'] = \"mlogloss\"\n",
    "\tparam['min_child_weight'] = 2\n",
    "\tparam['subsample'] = 0.9\n",
    "\tparam['colsample_bytree'] = 0.7\n",
    "\tparam['seed'] = 0\n",
    "\tparam['nthread']=8    \n",
    "\t#param['alpha']=0.2\n",
    "\t#param['lambda']=0.8\n",
    "\tnum_rounds = 110\n",
    "\tglobal target_cols\n",
    "\tplst = list(param.items())\n",
    "\treturn plst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "tr_x,te_x,tr_y,te_y=cross_validation.train_test_split(have_x,have_y,train_size=0.8,random_state=0)\n",
    "xgtrain=xgb.DMatrix(tr_x,label=tr_y)\n",
    "xgtest=xgb.DMatrix(te_x,label=te_y)\n",
    "model_have=xgb.train(model_xgboost(),xgtrain,150,evals=[(xgtrain,'train'),(xgtest,'test')],early_stopping_rounds=100)\n",
    "model_have.save_model(\"model_have_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "model_have=xgb.Booster(model_file='model_have_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### grid_search to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param={'max_depth':range(3,9,2),'min_child_weight':range(1,5,2)}\n",
    "scv=GridSearchCV(XGBClassifier(max_depth=6,min_child_weight=3,n_estimators=56,learning_rate=0.3,subsample=1,\n",
    "                               colsample_bytree=0.9,objective='multi:softprob'),param_grid=param,cv=5,n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict\n",
    "- ## separate the null and have to predict the result and merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the top products..\n"
     ]
    }
   ],
   "source": [
    "res=model_null.predict(xgb.DMatrix(np.array(test_x_1)[:,:18]))\n",
    "preds=res\n",
    "print(\"Getting the top products..\")\n",
    "target_cols = np.array(target_cols)\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:,:8]\n",
    "\n",
    "test_id = np.array(pd.read_csv(data_path+\"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "final_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "res_null=[]\n",
    "for i in range(len(test_x_1)):\n",
    "    if sum(test_x_1[i][18:])==0:\n",
    "        res_null.append([test_id[i],final_preds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the top products..\n"
     ]
    }
   ],
   "source": [
    "res=model_have.predict(xgb.DMatrix(test_x_1))\n",
    "preds=res\n",
    "print(\"Getting the top products..\")\n",
    "target_cols = np.array(target_cols)\n",
    "preds = np.argsort(preds, axis=1)\n",
    "preds = np.fliplr(preds)[:,:8]\n",
    "test_id = np.array(pd.read_csv(data_path+\"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "final_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "res_have=[]\n",
    "for i in range(len(test_x_1)):\n",
    "    if sum(test_x_1[i][18:])!=0:\n",
    "        res_have.append([test_id[i],final_preds[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res_predict=res_null+res_have\n",
    "res_fin=np.array(res_predict)\n",
    "out_df = pd.DataFrame({'ncodpers':res_fin[:,0], 'added_products':res_fin[:,1]})\n",
    "out_df.to_csv(data_path+'sub_xgb_lessMore_merge_null_2_v109.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ## model_all to predict the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting the top products..\n"
     ]
    }
   ],
   "source": [
    "\tres=model.predict(xgb.DMatrix(test_x_1))\n",
    "\tpreds=res\n",
    "\tprint(\"Getting the top products..\")\n",
    "\ttarget_cols = np.array(target_cols)\n",
    "\tpreds = np.argsort(preds, axis=1)\n",
    "\tpreds = np.fliplr(preds)[:,:8]\n",
    "\ttest_id = np.array(pd.read_csv(data_path+\"test_ver2.csv\", usecols=['ncodpers'])['ncodpers'])\n",
    "\tfinal_preds = [\" \".join(list(target_cols[pred])) for pred in preds]\n",
    "\tout_df=pd.DataFrame({'ncodpers':test_id, 'added_products':final_preds})\n",
    "\tout_df.to_csv(data_path+'sub_xgb_lessMore_merge_over11.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
